{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4558742,"sourceType":"datasetVersion","datasetId":2660745}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nfrom transformers import GPT2Tokenizer, GPT2LMHeadModel\nfrom transformers import DataCollatorForLanguageModeling, Trainer, TrainingArguments\nfrom transformers import pipeline\nfrom datasets import load_dataset\nfrom dataclasses import dataclass\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T10:59:16.317363Z","iopub.execute_input":"2025-05-19T10:59:16.317957Z","iopub.status.idle":"2025-05-19T10:59:16.322121Z","shell.execute_reply.started":"2025-05-19T10:59:16.317932Z","shell.execute_reply":"2025-05-19T10:59:16.321261Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"@dataclass\nclass GPT2Config:\n    model_name: str = \"gpt2\"\n    input_file: str = \"/kaggle/input/the-bards-best-a-character-modeling-dataset/train.csv\"\n    block_size: int = 128\n    batch_size: int = 32\n    num_epochs: int = 5000\n    save_steps: int = 1000\n    logging_steps: int = 500\n    output_dir: str = \"./shakespeare-gpt2\"\n    logging_dir: str = \"./logs\"\n    fp16: bool = torch.cuda.is_available()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T10:53:36.270985Z","iopub.execute_input":"2025-05-19T10:53:36.271572Z","iopub.status.idle":"2025-05-19T10:53:36.276728Z","shell.execute_reply.started":"2025-05-19T10:53:36.271551Z","shell.execute_reply":"2025-05-19T10:53:36.276030Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"config = GPT2Config()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T10:53:36.278411Z","iopub.execute_input":"2025-05-19T10:53:36.278656Z","iopub.status.idle":"2025-05-19T10:53:36.318382Z","shell.execute_reply.started":"2025-05-19T10:53:36.278630Z","shell.execute_reply":"2025-05-19T10:53:36.317752Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"tokenizer = GPT2Tokenizer.from_pretrained(config.model_name)\ntokenizer.pad_token = tokenizer.eos_token  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T10:53:36.318999Z","iopub.execute_input":"2025-05-19T10:53:36.319303Z","iopub.status.idle":"2025-05-19T10:53:40.959996Z","shell.execute_reply.started":"2025-05-19T10:53:36.319285Z","shell.execute_reply":"2025-05-19T10:53:40.959212Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9c7cef16a714e75ae6303763f6cbd73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"577c2be1e0b94befa7dba873d77d29a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f0d8a31579a4ba1bebf8d7189f019ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4188e72965e47529ce69d8b26a1a1fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cf2f56cfd3347adb28ea58bc2c933c3"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"dataset = load_dataset(\"csv\", data_files={\"train\": config.input_file})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T10:53:40.960779Z","iopub.execute_input":"2025-05-19T10:53:40.961064Z","iopub.status.idle":"2025-05-19T10:53:41.665868Z","shell.execute_reply.started":"2025-05-19T10:53:40.961040Z","shell.execute_reply":"2025-05-19T10:53:41.665342Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3546157b520432b915fb59c17dfcfdb"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"def tokenize(data):\n    tokens = tokenizer(\n        data[\"text\"],\n        truncation=True,\n        padding=\"max_length\",\n        max_length=config.block_size,\n    )\n    tokens[\"labels\"] = tokens[\"input_ids\"].copy()\n    return tokens\n\ntokenized_dataset = dataset.map(tokenize, remove_columns=[\"text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T10:53:41.666568Z","iopub.execute_input":"2025-05-19T10:53:41.666825Z","iopub.status.idle":"2025-05-19T10:53:44.334165Z","shell.execute_reply.started":"2025-05-19T10:53:41.666772Z","shell.execute_reply":"2025-05-19T10:53:44.333617Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f72b7633e3a945609e4782e107bdec6d"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"model = GPT2LMHeadModel.from_pretrained(config.model_name)\nmodel.config.pad_token_id = model.config.eos_token_id \n\ncollator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T10:53:44.334881Z","iopub.execute_input":"2025-05-19T10:53:44.335157Z","iopub.status.idle":"2025-05-19T10:53:48.551572Z","shell.execute_reply.started":"2025-05-19T10:53:44.335133Z","shell.execute_reply":"2025-05-19T10:53:48.550690Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"446dc3dc53eb450bbf67a28642871e50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49ab4da5423948adac60c0941bc002c8"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=config.output_dir,\n    overwrite_output_dir=True,\n    num_train_epochs=config.num_epochs,\n    per_device_train_batch_size=config.batch_size,\n    save_steps=config.save_steps,\n    save_total_limit=2,\n    logging_dir=config.logging_dir,\n    logging_steps=config.logging_steps,\n    prediction_loss_only=True,\n    report_to=\"none\", \n    fp16=config.fp16,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset[\"train\"],\n    data_collator=collator,\n)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T10:53:48.552420Z","iopub.execute_input":"2025-05-19T10:53:48.552723Z","iopub.status.idle":"2025-05-19T10:59:06.762516Z","shell.execute_reply.started":"2025-05-19T10:53:48.552703Z","shell.execute_reply":"2025-05-19T10:59:06.761932Z"}},"outputs":[{"name":"stderr","text":"`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5000/5000 05:16, Epoch 5000/5000]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.107500</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.002400</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.002000</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.000600</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.000200</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.000400</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.000200</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.000300</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.000200</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=5000, training_loss=0.011380765021778642, metrics={'train_runtime': 317.4139, 'train_samples_per_second': 15.752, 'train_steps_per_second': 15.752, 'total_flos': 326615040000000.0, 'train_loss': 0.011380765021778642, 'epoch': 5000.0})"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"model.save_pretrained(config.output_dir)\ntokenizer.save_pretrained(config.output_dir)\n\nprint(f\"Model saved to: {config.output_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T10:59:06.764171Z","iopub.execute_input":"2025-05-19T10:59:06.764384Z","iopub.status.idle":"2025-05-19T10:59:07.920699Z","shell.execute_reply.started":"2025-05-19T10:59:06.764367Z","shell.execute_reply":"2025-05-19T10:59:07.920049Z"}},"outputs":[{"name":"stdout","text":"Model saved to: ./shakespeare-gpt2\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n\nprint(generator(\"The King has returned \", max_length=150)[0][\"generated_text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T12:44:03.260745Z","iopub.execute_input":"2025-05-19T12:44:03.261344Z","iopub.status.idle":"2025-05-19T12:44:05.097879Z","shell.execute_reply.started":"2025-05-19T12:44:03.261322Z","shell.execute_reply":"2025-05-19T12:44:05.097101Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"The King has returned ****************\n\nAll:\nSpeak, speak.\n\nFirst Citizen:\nYou are all resolved rather to die than to famish?\n\nAll:\nResolved. resolved.\n\nFirst Citizen:\nFirst, you know Caius Marcius is chief enemy to the people.\n\nAll:\nWe know't, we know't.\n\nFirst Citizen:\nLet us kill him, and we'll have corn at our own price.\nIs't a verdict?\n\nAll:\nNo more talking on't; let it be.\n\nFirst Citizen:\nLet us kill him, and we'll have corn at our own price.\nIs't a verdict?\n\n\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}